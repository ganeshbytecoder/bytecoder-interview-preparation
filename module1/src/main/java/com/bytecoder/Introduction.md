* how are you ? . how's your day so far ?
* I'm Ganesh. i am currently living in North carolina , Cary, working as a senior software engineer in smattrack ->
*
* I have around 6 years of experience in software development and working in AI company, focusing on backend engineering and big data processing. my focus to build **scalable, secure and distributed systems**
* I’ve worked extensively with Java and Spring Boot, kafka , Docker , aws and DB followed by expertise in large-scale data processing with PySpark and create features for DS,
* which has helped me optimize and scale big data applications like
* **Responsibility
  leading team of 7 devs**

  development , Code review, brainstorming for new features and technical aspects
  mentor juniors
  Features development and testing and handing over to QA for release and further testing
  Documents
  Architect or design technical design of new features
  planning

  **Fourkites and Rupeek
  started my career as as software engineer**

    * Fourkites -> build a network to invite their shipper and get live details to track the containers and carriers
    * **Rupeek**

        * build a dashboard for live CICD analysis -> deployments, alerts , changes in configs and infra alerts in one consolidated platform
        * Dockerised all applcations 40+ , best practices , env egnostic,
        * hashicorp vault integration , k8s and CICD pipelines in AWS

      **Kaleidofin**

        * **risk-infra** ,  partners and onboarding for loans and transaction and **integration of multi-tanent architecture** -> processing around 50 million dollar worth of loans every year -> kiview and kiscore
        * created ML model features for DS and reduces processing time from 33 hours to 10 hours only.
    * **Smarttrak**

        * new features development in spring boot, java, kafka, aws services, DB(postgres, cassandra)
        * plants onboarding service-> **integration of multi-tanent architecture ->**
        * **Developed a high-performance PySpark pipeline reducing processing time from 27 hours to under 50 minutes, enabling to create ML features for our LLM and machine learning models**
        * Developed centralized Authentication service in spring security
        * **helping in building digital twins and physics based AI model**
* **Achievements**

    * top impactors
    * rupeek infra migration
    * risk-infra
    * multi tenant architecture
* I have some hands-on experience with React.js for frontend work.
* Amazon values engineers who can **build scalable and secured backend systems** and work with  **large datasets efficiently** .
*
* **Scalability:** “In my recent projects, I designed and optimized microservices handling millions of transactions, ensuring low latency and high availability and secured services.”
* **Distributed Systems:** “I've worked on distributed data pipelines in PySpark, optimizing large-scale batch and streaming jobs.”
* **Performance Tuning:** “I’ve optimized loan approval performance and backend APIs to handle high-throughput workloads efficiently.”
*

**Why you wann switch**

* Have build mutile pipelines and features and security services
* Now I don’t have anything interesting work which i am looking for a opportunity where i can use my expereince and learn

**I have experience in building product or features where it is highly secure and serving 2 3 million people max.**

But the meta has is in billions which excite me that how things work there

How they devs decides features, tech and other things

So I wanna part of that team which has that much ammount of scale . And contribute my expertise n learn new things

**also cherry on cake i am learning and working on new tech like agentic and digital twin architecture** ,

Good understanding of  Ml model features

here things are stagnant

about company and productions

what project i will be working

what is the role and responsiblities


**Built highly scalable backend features with Kafka and time-series db to visualize data for a real-time monitoring dashboard.**

Designed architecture to handle real time data processing and developed highly scalable backend features for digital twins and real-time system analysis for solar plants.

**Developed centralized Authentication service in spring security** and role based features for the dashboard

**Developed a high-performance PySpark pipeline reducing batch processing time from 27 hours to under 50 minutes, enabling to creation of features for our LLM Agents and machine-learning models. which help reduced our turn-around time for our new partners onboarding**



* how are you ? . how's your day so far ?

what will be process of interview -> 

is there leadership principles gonna be asked ?

what are the key points to remember ?

any suggested topics and questions to revise before interview ?